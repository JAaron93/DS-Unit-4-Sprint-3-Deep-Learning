{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FrankenBERT_Labs37.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM0AbnCw2Ppko6eXcddtz+k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAaron93/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/FrankenBERT_Labs37.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwVmV4rPJCa7"
      },
      "source": [
        "# Reading in our Tweets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEH0zNz2FO_K",
        "outputId": "820b17f8-2053-4b8b-8773-c4bb43e80d7b"
      },
      "source": [
        "!pip install pyforest\n",
        "!pip install transformers\n",
        "!pip install psycopg2-binary\n",
        "!pip uninstall -y tensorflow-datasets\n",
        "!pip install lit_nlp tfds-nightly transformers==4.1.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyforest\n",
            "  Downloading pyforest-1.1.0.tar.gz (15 kB)\n",
            "Building wheels for collected packages: pyforest\n",
            "  Building wheel for pyforest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyforest: filename=pyforest-1.1.0-py2.py3-none-any.whl size=14607 sha256=6b4504b4f31f3527656083c395368ae80515b0273ddd1f87c42f1ae25802d987\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/1c/da/48e6c884142d485475d852d69d20a096aba5beceb338822893\n",
            "Successfully built pyforest\n",
            "Installing collected packages: pyforest\n",
            "Successfully installed pyforest-1.1.0\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 13.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 40.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 44.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 41.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 13.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
            "Successfully installed psycopg2-binary-2.9.1\n",
            "Found existing installation: tensorflow-datasets 4.0.1\n",
            "Uninstalling tensorflow-datasets-4.0.1:\n",
            "  Successfully uninstalled tensorflow-datasets-4.0.1\n",
            "Collecting lit_nlp\n",
            "  Downloading lit_nlp-0.3-py3-none-any.whl (599 kB)\n",
            "\u001b[K     |████████████████████████████████| 599 kB 11.8 MB/s \n",
            "\u001b[?25hCollecting tfds-nightly\n",
            "  Downloading tfds_nightly-4.4.0.dev202108220107-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 40.0 MB/s \n",
            "\u001b[?25hCollecting transformers==4.1.1\n",
            "  Downloading transformers-4.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 44.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (4.62.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (3.0.12)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 34.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (21.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (0.22.2.post1)\n",
            "Requirement already satisfied: Werkzeug in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (1.0.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (0.12.0)\n",
            "Collecting ml-collections\n",
            "  Downloading ml_collections-0.1.0-py3-none-any.whl (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (21.2.0)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (1.3.9)\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (1.1.5)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (5.2.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (0.3.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (3.0.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tfds-nightly) (3.5.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml-collections->lit_nlp) (0.5.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml-collections->lit_nlp) (5.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.1.1) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->lit_nlp) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->lit_nlp) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->lit_nlp) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (1.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tfds-nightly) (1.53.0)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn->lit_nlp) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.4.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 27.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn->lit_nlp) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn->lit_nlp) (0.34.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76564 sha256=6f197ad27f55516b0330763d26f7e715260ea7c189a03972bd1d0b1235c1a413\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/e7/bb/347dc0e510803d7116a13d592b10cc68262da56a8eec4dd72f\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.4-py3-none-any.whl size=52373 sha256=30b8e63d1436ae43a81eea113426a7bf3c5a4d104ae6102b6e857ad48b222c54\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/5b/62/3401692ddad12324249c774c4b15ccb046946021e2b581c043\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, portalocker, colorama, umap-learn, tokenizers, sacrebleu, ml-collections, transformers, tfds-nightly, lit-nlp\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.10.3\n",
            "    Uninstalling tokenizers-0.10.3:\n",
            "      Successfully uninstalled tokenizers-0.10.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.9.2\n",
            "    Uninstalling transformers-4.9.2:\n",
            "      Successfully uninstalled transformers-4.9.2\n",
            "Successfully installed colorama-0.4.4 lit-nlp-0.3 ml-collections-0.1.0 portalocker-2.3.1 pynndescent-0.5.4 sacrebleu-2.0.0 tfds-nightly-4.4.0.dev202108220107 tokenizers-0.9.4 transformers-4.1.1 umap-learn-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WP4yh9fRFSrq",
        "outputId": "6371c434-1411-4ca5-a983-54e8bd9dfc08"
      },
      "source": [
        "# Imports\n",
        "from pyforest import *\n",
        "pd.options.display.max_colwidth = 750\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from lit_nlp import notebook"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suBn1jFAFVbW"
      },
      "source": [
        "def rank_wrangle():\n",
        "  '''\n",
        "  Loads in both synthetic tweets generated from GPT-2 and authentic tweets from scraped from Twitter.\n",
        "  Performs transformations for the sake of placing our data into a format amicable to NLP modeling.\n",
        "  -----\n",
        "  Training and test .csv files are contained within /Labs36_notebooks.\n",
        "  rank2_syn.txt, rank3_syn.txt, and rank4_syn.txt are found in /synthetic_tweets\n",
        "  -----\n",
        "  Parameters \n",
        "  ------\n",
        "  None\n",
        "  Returns\n",
        "  -------\n",
        "  df: pandas dataframe\n",
        "  Contains fully concatenated dataframe\n",
        "  '''\n",
        "  # Supplying our dataframes with proper labels\n",
        "  column_headers = ['tweets', 'labels']\n",
        "  # Reading in our three police force rank datasets\n",
        "  df_rank2 = pd.read_csv(\"/content/rank2_syn.txt\",\n",
        "                       sep = '/',\n",
        "                       names=column_headers)\n",
        "  df_rank3 = pd.read_csv(\"/content/rank3_syn.txt\",\n",
        "                       sep = '/',\n",
        "                       names=column_headers)\n",
        "  df_rank4 = pd.read_csv(\"/content/rank4_syn.txt\",\n",
        "                       sep = '/',\n",
        "                       names=column_headers)\n",
        "  train = pd.read_csv('/content/training.csv')\n",
        "  test = pd.read_csv('/content/test.csv')\n",
        "  # Concatenating all of our datasets into one\n",
        "  compiled = pd.concat([train, test, df_rank2, df_rank3, df_rank4])\n",
        "  # Dropping unnecessary columns\n",
        "  compiled.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "  compiled.drop('id', axis=1, inplace=True)\n",
        "  # Discarding generated duplicates from GPT-2 while keeping the original Tweets\n",
        "  compiled.drop_duplicates(subset='tweets', keep='first', inplace=True)\n",
        "\n",
        "  return compiled"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "JIxVazavHLaJ",
        "outputId": "488855d5-d8c0-4d46-a536-d0ceb0ae7fa7"
      },
      "source": [
        "# Applying our function above and viewing the contents of our dataframe\n",
        "force_ranks = rank_wrangle()\n",
        "force_ranks"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A New Mexico State Police officer killed two people in crisis within five weeks, and demands for accountability are mounting https://t.co/mFYfC7kTFQ</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I found some police badge stickers at work and I’ve started asking every officer I see if they want one with their name on it. I think it’s funny every time and so do they so I will continue this</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>According to media reports, police said they arrested Sharma after a complaint from animal welfare organisation People for Animals. | via @philstarlife https://t.co/DO5ZZlNJHs</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The male who has the knife is now running northbound, per caller.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Changing the assignments of already existing cops and diverting already existing resources means you wouldn’t have increase the police budget.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>917</th>\n",
              "      <td>Following the death of an unarmed driver at the hands of police, protesters gathered outside the Miami Police Department. Footage shows a woman screaming and in sufficient pain that another protester is needed to carry her away quickly. Other protesters come to aid her and are summarily pepper-sprayed.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>920</th>\n",
              "      <td>At a protest outside the ICE facility in Portland, protesters built a barricade and threw objects at ICE agents and officers. Federal agents then deployed tear gas and stun grenades against the crowd.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921</th>\n",
              "      <td>Following the death of an unarmed driver at the hands of police, protesters gathered outside the Brooklyn Center police precinct. Around 9pm, police fired tear gas and rubber bullets into the crowd.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>922</th>\n",
              "      <td>A journalist with Mill City Citizen Media is shot to death outside a Shake Shack restaurant after refusing to leave the building. The man was wearing a press jacket and held a sign above his head saying he was not allowed to be on the internet. Police said the man’s name was James Borden and he was receiving medical attention while hospitalized. He was shot once through the head and died shortly afterward. Mill City is about an hour away from Portland./4\\r\\nFollowing the death of an unarmed driver at the hands of police, protesters gathered outside the Brooklyn Center police precinct. Police there had been called to the precinct multiple times about a large fight and other protesters disruptive behavior. Police had deployed tear gas and...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>Video shows sound cannon deployed alongside APC. The LRAD can be heard with its characteristic alarm. The use of LRADs is a subject of much contention, with frequent reports of permanent nerve and hearing damage caused by their use. The ACLU’s position is that due to the high risk of damage and lack of research on lasting effects, use is illegal under most circumstances.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6995 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            tweets  labels\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             A New Mexico State Police officer killed two people in crisis within five weeks, and demands for accountability are mounting https://t.co/mFYfC7kTFQ       5\n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              I found some police badge stickers at work and I’ve started asking every officer I see if they want one with their name on it. I think it’s funny every time and so do they so I will continue this       0\n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  According to media reports, police said they arrested Sharma after a complaint from animal welfare organisation People for Animals. | via @philstarlife https://t.co/DO5ZZlNJHs       1\n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The male who has the knife is now running northbound, per caller.       0\n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Changing the assignments of already existing cops and diverting already existing resources means you wouldn’t have increase the police budget.       0\n",
              "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ...     ...\n",
              "917                                                                                                                                                                                                                                                                                                                                                                                                                                                                Following the death of an unarmed driver at the hands of police, protesters gathered outside the Miami Police Department. Footage shows a woman screaming and in sufficient pain that another protester is needed to carry her away quickly. Other protesters come to aid her and are summarily pepper-sprayed.       4\n",
              "920                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       At a protest outside the ICE facility in Portland, protesters built a barricade and threw objects at ICE agents and officers. Federal agents then deployed tear gas and stun grenades against the crowd.       4\n",
              "921                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Following the death of an unarmed driver at the hands of police, protesters gathered outside the Brooklyn Center police precinct. Around 9pm, police fired tear gas and rubber bullets into the crowd.       4\n",
              "922  A journalist with Mill City Citizen Media is shot to death outside a Shake Shack restaurant after refusing to leave the building. The man was wearing a press jacket and held a sign above his head saying he was not allowed to be on the internet. Police said the man’s name was James Borden and he was receiving medical attention while hospitalized. He was shot once through the head and died shortly afterward. Mill City is about an hour away from Portland./4\\r\\nFollowing the death of an unarmed driver at the hands of police, protesters gathered outside the Brooklyn Center police precinct. Police there had been called to the precinct multiple times about a large fight and other protesters disruptive behavior. Police had deployed tear gas and...       4\n",
              "923                                                                                                                                                                                                                                                                                                                                                                                          Video shows sound cannon deployed alongside APC. The LRAD can be heard with its characteristic alarm. The use of LRADs is a subject of much contention, with frequent reports of permanent nerve and hearing damage caused by their use. The ACLU’s position is that due to the high risk of damage and lack of research on lasting effects, use is illegal under most circumstances.       4\n",
              "\n",
              "[6995 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrXu1czPQ_Of",
        "outputId": "4b01f10b-9872-4c90-b261-131bc51d3f7d"
      },
      "source": [
        "force_ranks.isnull().sum()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweets    0\n",
              "labels    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGUMT3M6IVaN"
      },
      "source": [
        "## Number of Tweets per Label - Visualized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Zb9W6AUUIUqp",
        "outputId": "3dd48265-2120-4fe9-b4ef-2b4ddc8ac10d"
      },
      "source": [
        "force_ranks.labels.value_counts(ascending=True).plot(kind='barh')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7ceef75250>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buKtNgt0Ika5"
      },
      "source": [
        "Ranks 2, 3, and 4 are still paltry in comparison to ranks 0, 1, & 5. However, the number we have here for each of these three ranks, >500, should still be enough to solve BERT's class imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3iuUK_pIsCa"
      },
      "source": [
        "# Preparing Data for BERT\n",
        "\n",
        "Splitting dataframe into training and testing sets before converting to parquet for later reference/resource."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cmyr6PhuIkHF",
        "outputId": "1bd03226-228a-4a34-e656-0cd6d0e5f6b2"
      },
      "source": [
        "training, testing = train_test_split(force_ranks, test_size=0.2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZlEP09MJMEl",
        "outputId": "36996b76-87ea-4af4-b3cb-0871ee3c79bd"
      },
      "source": [
        "# Sanity Check\n",
        "len(force_ranks) == len(training) + len(testing)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U2CcoxuJOx1"
      },
      "source": [
        "training.to_parquet('synthetic_training.parquet')\n",
        "testing.to_parquet('synthetic_testing.parquet')\n",
        "force_ranks.to_parquet('synthetic_complete.parquet')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb31wbWNJ17v"
      },
      "source": [
        "# BERT - Training our NLP Multi Class Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQNUUmx_Jz1j"
      },
      "source": [
        "def bert_trainer(df, output_dir: str, epochs: int):\n",
        "    max_len = 280\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"CUDA Active\")\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        print(\"CPU Active\")\n",
        "        device = torch.device(\"cpu\")\n",
        "    sentences = df[\"tweets\"].values\n",
        "    labels = df[\"labels\"].values\n",
        "    tokenizer = BertTokenizer.from_pretrained(\n",
        "        'bert-base-uncased',\n",
        "        do_lower_case=True,\n",
        "    )\n",
        "    inputs = [\n",
        "        tokenizer.encode(sent, add_special_tokens=True) for sent in sentences\n",
        "    ]\n",
        "    inputs_ids = pad_sequences(\n",
        "        inputs,\n",
        "        maxlen=max_len,\n",
        "        dtype=\"long\",\n",
        "        value=0,\n",
        "        truncating=\"post\",\n",
        "        padding=\"post\",\n",
        "    )\n",
        "    attention_masks = [\n",
        "        [int(token_id != 0) for token_id in sent] for sent in inputs_ids\n",
        "    ]\n",
        "    train_inputs = torch.tensor(inputs_ids)\n",
        "    train_labels = torch.tensor(labels)\n",
        "    train_masks = torch.tensor(attention_masks)\n",
        "    batch_size = 32\n",
        "    train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(\n",
        "        train_data,\n",
        "        sampler=train_sampler,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        'bert-base-uncased',\n",
        "        num_labels=6,\n",
        "        output_attentions=False,\n",
        "        output_hidden_states=False,\n",
        "    )\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps,\n",
        "    )\n",
        "    loss_values = []\n",
        "    print('\\nTraining...')\n",
        "    for epoch_i in range(1, epochs + 1):\n",
        "        print(f\"\\nEpoch: {epoch_i}\")\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "            model.zero_grad()\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask,\n",
        "                labels=b_labels,\n",
        "            )\n",
        "            loss = outputs[0]\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        loss_values.append(avg_train_loss)\n",
        "        print(f\"Average Loss: {avg_train_loss}\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    print(f\"\\nSaving model to {output_dir}\")\n",
        "    model_to_save = model.module if hasattr(model, 'module') else model\n",
        "    model_to_save.save_pretrained(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    print(\"Finished!\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "hCnOUmjCKMil",
        "outputId": "e09f43eb-3d4b-49a7-ee11-fbb49b992803"
      },
      "source": [
        "bert_trainer(training, 'saved_model', epochs=50)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2df9a5f1f43c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saved_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'bert_trainer' is not defined"
          ]
        }
      ]
    }
  ]
}