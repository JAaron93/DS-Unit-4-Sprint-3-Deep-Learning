{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DS16 LS_DS_441_RNN_and_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "py37  (Python3)",
      "language": "python",
      "name": "py37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAaron93/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Lecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldr0HZ193GKb"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 3, Module 1*\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et2y0gP7IM19"
      },
      "source": [
        "# Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTM) (Prepare)\n",
        "\n",
        "![](https://wiki.tum.de/download/attachments/22578349/GATES.gif?version=1&modificationDate=1486083227237&api=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BOMScPtIM1-"
      },
      "source": [
        "## Learning Objectives\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IizNKWLomoA"
      },
      "source": [
        "-----\n",
        "# Overview\n",
        "\n",
        "### Let's start with sequences \n",
        "\n",
        "A sequence is just any collection of numbers - order counts and repetition is allowed. \n",
        "\n",
        "Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list and is different from `[1, 2, -1, 2]`. \n",
        "\n",
        "What you might not be as familiar with are recusive numbers. For that, let's talk about a specific example, namely the **Fibonacci Sequence**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44QZgrPUe3-Y"
      },
      "source": [
        "# Neural Networks for Sequences (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX_WLYHrIM1_"
      },
      "source": [
        "\n",
        "\n",
        "Before we dive into the inner workings of an LSTM model, let's try to understand and appreciate the recusive relationships of numbers in both pure mathematics and in the physical reality in which we find ourselves embedded. \n",
        "\n",
        "\n",
        "As usually we take attempt to understand a concept from at least 3 different perspectives:\n",
        "- Algebraic\n",
        "- Geometric\n",
        "- Coding an example\n",
        "\n",
        "\n",
        "A [**recurrence relation**](https://en.wikipedia.org/wiki/Recurrence_relation) in math is an equation that uses recursion to define a sequence of numbers - a famous example is the Fibonacci numbers.\n",
        "\n",
        "Here is the algorithm for generating the numbers in the Fibonacci sequence: \n",
        "\n",
        "$$F_n = F_{n-1} + F_{n-2}$$\n",
        "\n",
        "You need a base case $F_0=1, F_1=1$ (i.e. a starting point) to get the sequence started and then from then on our the sequence is self-generating. \n",
        "\n",
        "So this means that we can start generating our sequence: \n",
        "\n",
        "$$F_0=1,~~  F_1=1 $$\n",
        "\n",
        "$$F_2 = F_{1} + F_{0} ~=~ 1 + 1 ~=~ 2$$\n",
        "\n",
        "Then\n",
        "\n",
        "$$F_3 = F_{2} + F_{1} ~=~ 2 + 1 ~=~ 3$$\n",
        "\n",
        "Then \n",
        "\n",
        "$$F_4 = F_{3} + F_{2} ~=~ 3 + 2 ~=~ 5$$\n",
        "\n",
        "Then \n",
        "\n",
        "$$F_5 = F_{4} + F_{3} ~=~ 5 + 3 ~=~ 8$$\n",
        "\n",
        "I hope you get the idea. \n",
        "\n",
        "Before we we code up this sequence, let's appreciate how important and ubiquitous it is in nature. \n",
        "\n",
        "![](http://www.davidbeahm.com/wp-content/uploads/2011/11/fibonacci-1024x637.jpg)\n",
        "\n",
        "\n",
        "![](https://i.pinimg.com/originals/32/d7/47/32d747bea24f4756dc4c5ffe61b36efd.jpg)\n",
        "\n",
        "![](https://i.pinimg.com/originals/f2/cb/34/f2cb3452dd774bab87bbee2b8a77d4bb.png)\n",
        "\n",
        "\n",
        "![](https://f4.bcbits.com/img/a3628582449_10.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ROfJbJrSIRL"
      },
      "source": [
        "**Take Away:** \n",
        "- Recursive sequences are located everywhere in life - but we need to know what we're looking for and where to look for it. \n",
        "- Simply try to develop an appreciation for the connection between mathematics and all of physical reality. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hFbLYRJSIRM"
      },
      "source": [
        "### Code up the Fibonacci Sequence\n",
        "Again, here is the algorithm for the Fibonacci numbers.  \n",
        "\n",
        "\n",
        "$$F_n = F_{n-1} + F_{n-2}$$\n",
        "\n",
        "\n",
        "You need a base case to get your sequence started. This time let  $F_0=0 ~\\text{and}~ F_1=1$. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_BJcBuYSIRN"
      },
      "source": [
        "def fibo(n):\n",
        "    \"\"\"\n",
        "    Calculate and return the next number in the Fibonacci sequence\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    n: int or float\n",
        "        The nth number in the sequence (think of it as an index for a list)\n",
        "        \n",
        "    Return\n",
        "    ------\n",
        "    F_n: the next number in the sequence generated from the previous two numbers in the sequence \n",
        "    \"\"\"\n",
        "    \n",
        "    if n <= 1:\n",
        "        # if n = 0, then return 0 \n",
        "        return n\n",
        "    else:\n",
        "        # this is the recursive part \n",
        "        # notice how the function is a function of itself!\n",
        "        #  F_n =       F_n-1 + F_n-2\n",
        "        return(fibo(n-1) + fibo(n-2))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d5757486eecafe9c2c1af5b428e482b3",
          "grade": false,
          "grade_id": "cell-b31ecb0aaf3ace76",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxVbn4fLSIRO",
        "outputId": "024db588-5ce8-4202-814d-08120ea0e4e4"
      },
      "source": [
        "# generate a Fibonacci Sequence\n",
        "# YOUR CODE HERE\n",
        "#let n be the length of our fibo sequence\n",
        "n = 10\n",
        "[fibo(num) for num in range(n)]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01rG-2gqSIRO"
      },
      "source": [
        "**Take Away:** \n",
        "\n",
        "Recursive algorithms have as input their previous output. In order words, the output at time step `t - 1`, becomes in the input in the following time step `t`. This is the key idea of that you should observe. Because it is this recursive behavior that is new to how we will think about neural networks, specifically the LSTM model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hah7DlpdSIRP"
      },
      "source": [
        "-----\n",
        "\n",
        "## Introduction to Recursive Neural Networks (RNNs) \n",
        "\n",
        "\n",
        "The nice thing about spending time to understand the Fibonacci Sequence is that we can then `borrow the intuition` that we picked up to help us understand how the LSTM works. \n",
        "\n",
        "Different Recursive Neural Networks (RNNs) have this recursive loop in their architecture. The ML research community first created the following RNN model using the standard Fully-Connected Forward Feeding (FCFF) model: \n",
        "\n",
        "![](https://nerdthecoder.files.wordpress.com/2019/02/731df-0mrhhgabskajpbt21.png)\n",
        "\n",
        "`This type of RNN had severe limitations!` \n",
        "\n",
        "- It didn't have long-term memory capacity to learn long input sequences \n",
        "- It suffered from the [Vanishing Gradient Problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem).\n",
        "\n",
        "In response to these limitations, the ML research community created the LSTM model, which ditched the FCFF architecture and started using the following architecture:\n",
        "\n",
        "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
        "\n",
        "Wow! Ok! There's a lot going on here, isn't there? Well, don't worry, we are going to break this model down bit-by-bit so we can understand what is happening. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxuq0AFeSIRQ"
      },
      "source": [
        "_____\n",
        "\n",
        "\n",
        "## Theory of LSTM\n",
        "\n",
        "One of the simplist and clearest explanations of the LSTM model can be found [**here!**](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) - a beautifully clear and concise explaination the model's archtecture and the mathematics. This link will serve as our main resouce for understanding how LSTMs work. \n",
        "\n",
        "Below are the equations for each of the gates that are explained in the article. \n",
        "\n",
        "Although, you will not be held responsible for the equations in any quiz, module assignment, or Sprint Challenge - it is still instructive to be exposed to them at least once.\n",
        "\n",
        "First thing to notice is that each gate equation (not the cell states) has the form of a perceptron. \n",
        "\n",
        "`Remember the perceptron?` It's the fundamental building block of neural networks - it's not going away! \n",
        "\n",
        "Once you understand that, it will hopefully become gradually clear that each gate is a perceptron with a different job to do. \n",
        "\n",
        "That's it. \n",
        "\n",
        "It's just 4 perceptrons, each with a different job to do. \n",
        "\n",
        "Fortunately, you already know about perceptrons (you built one from scratch in `Sprint 2 Module 1`). \n",
        "\n",
        "____\n",
        "\n",
        "### Gates in More Detail\n",
        "\n",
        "#### Forget Gate\n",
        "This neuron's job is to use the current input to learn what information the cell state should forget regarding long-term dependencies. \n",
        "\n",
        "\n",
        "$$f_t = \\sigma(W_f \\cdot [h_{t-1},x_t]~+~b_f)$$\n",
        "\n",
        "#### Input Gate\n",
        "This neuron's job is to use the current input to learn what new information to include in the cell state. \n",
        "\n",
        "\n",
        "$$i_t = \\sigma(W_i \\cdot [h_{t-1},x_t]~+~b_i)$$\n",
        "\n",
        "#### Candidate Cell State \n",
        "This neuron's job is to use the current input to create a candidate cell state.\n",
        "\n",
        "This new candidate cell state will be used to update the model's final cell state.\n",
        "\n",
        "$$\\tilde{C}_t = \\text{tanh}(W_C \\cdot [h_{t-1},x_t]~+~b_C)$$\n",
        "\n",
        "#### New Cell State\n",
        "This is where the candidate and old cell state are combined to create a new cell state.\n",
        "\n",
        "This is where output from the forget gate $f_t$ is used to scaled the old cell state\n",
        "\n",
        "- If $f_t$'s value is closer to 0.0, then less information from the previous cell state is retained.\n",
        "- If $f_t$'s value is closer to 1.0, then more information from the previous cell state is retained. \n",
        "\n",
        "\n",
        "This is also where the output of the input gate $i_t$ is used to scaled the candidate cell state. \n",
        "- If $i_t$'s value is closer to 0.0, then less information from the candidate cell state is retained\n",
        "- If $i_t$'s value is closer to 1.0, then more information from the candidate cell state is retained. \n",
        "\n",
        "Finally, you combine the two scaled cell states to form the new cell state of the model. \n",
        "\n",
        "It is $C_t$ that will be passed into the next training step and used by the output to make a final prediction. \n",
        "\n",
        "$$C_t = f_t*C_{t-1} + i_t*\\tilde{C}_t$$\n",
        "\n",
        "#### Output Gate\n",
        "This is where the actual output of the model is calcuated. \n",
        "\n",
        "The article denotes the model's pre-scaled output as $o_t$ and the scaled output as $h_t$. To be clear, it is $h_t$ that ultimately gets outputed as the model's final prediction. \n",
        "\n",
        "We are familiar with the notation $y$ to denote a model's prediction instead of using $h$. But they both mean the same thing - the model's final prediction. \n",
        "\n",
        "This neuron's job is to take the current input and make a prediction. \n",
        "\n",
        "$$o_t = \\sigma(W_o \\cdot [h_{t-1},x_t]~+~b_o)$$\n",
        "\n",
        "Next, the cell state is used to inform the final prediction. \n",
        "\n",
        "Recall that $o_t$ is output from a sigmoid activation function, so it's value is somewhere between 0 and 1. \n",
        "\n",
        "Which means that it is being used to scale $\\text{tanh}(C_t)$ which contains the current cell state. \n",
        "\n",
        "Recall the tanh curve and you'll see that tanh is scaling $C_t$ so that it's value lies between -1 and 1; this makes it possible to have positive and negative values for the model's output. Sigmoids don't allow for the posibility of negative values, but tanh does. \n",
        "\n",
        "$$h_t = o_t*\\text{tanh}(C_t)$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra2PxbLqSIRS"
      },
      "source": [
        "_________\n",
        "\n",
        "### Today's Application of LSTMs\n",
        "\n",
        "So why are these cool? \n",
        "\n",
        "One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n",
        "\n",
        "For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. \n",
        "\n",
        "Resources:\n",
        "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
        "- https://keras.io/layers/recurrent/#lstm\n",
        "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
        "\n",
        "Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWrQllf8WEd-"
      },
      "source": [
        "_____________\n",
        "\n",
        "\n",
        "## Follow Along\n",
        "\n",
        "Sequences come in many shapes and forms from stock prices to text. We'll focus on text, because modeling text as a sequence is a strength of Neural Networks. Let's start with a simple classification task using a TensorFlow tutorial. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSytcRhoIM2A"
      },
      "source": [
        "### RNN/LSTM Sentiment Classification with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti23G0gRe3kr"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.datasets import imdb\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBy7wP4USIRU",
        "outputId": "438a2b16-e7f4-425c-840f-daab420a442c"
      },
      "source": [
        "# load in dataset \n",
        "\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000 train sequences\n",
            "25000 test sequences\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XWP9TNEM8-q",
        "outputId": "be21fe29-9201-4c76-e36a-bbc03d9a17c2"
      },
      "source": [
        "# documentation on this data set here: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data\n",
        "# the values in the lists represents the token frequncy, so \"1\" means the most frequent token in the corpus \n",
        "# each list represents a movie review\n",
        "x_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6iD3a1VUa6d"
      },
      "source": [
        "max_features = 20000\n",
        "# This will be used later for out input layer"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK9k4UKJM9EC",
        "outputId": "bb677e96-8ddc-4d7c-fbe2-cd9de7173088"
      },
      "source": [
        "# binary labels \n",
        "# 1 -> positive sentiment expressed in movie review\n",
        "# 0 -> negative sentiment expressed in movie review \n",
        "num_unique_labels = len(np.unique(y_train))\n",
        "num_unique_labels"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "c0awRJCnIM2G",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "06de4d9b7986caa5aef6c537af138ee9",
          "grade": false,
          "grade_id": "cell-fb23c1d7d1168a73",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# although there are some implmentations of LSTM models that can handle variable length samples, this is not one of those models\n",
        "# so we need to standardize the length of our movies\n",
        "# reviews that are longer than maxlen are truncated\n",
        "# reivews that are shorter than maxlen are padded with 0 (Or some other value that you provide)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "maxlen = 80\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU5RC8csjFAf",
        "outputId": "9332d670-96cc-4ca6-af73-52adb6f9903a"
      },
      "source": [
        "# Trying out a for loop\n",
        "n = 10\n",
        "for i in range(n):\n",
        "  print (x_train[i].shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80,)\n",
            "(80,)\n",
            "(80,)\n",
            "(80,)\n",
            "(80,)\n",
            "(80,)\n",
            "(80,)\n",
            "(80,)\n",
            "(80,)\n",
            "(80,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7laq1FpESIRY"
      },
      "source": [
        "### Build a 1 hidden layer LSTM language model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob7GwCdbjtnd",
        "outputId": "87954a7d-1b85-4e26-b485-5ee8f8e60ed3"
      },
      "source": [
        " x_train[1]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 125,   68,    2, 6853,   15,  349,  165, 4362,   98,    5,    4,\n",
              "        228,    9,   43,    2, 1157,   15,  299,  120,    5,  120,  174,\n",
              "         11,  220,  175,  136,   50,    9, 4373,  228, 8255,    5,    2,\n",
              "        656,  245, 2350,    5,    4, 9837,  131,  152,  491,   18,    2,\n",
              "         32, 7464, 1212,   14,    9,    6,  371,   78,   22,  625,   64,\n",
              "       1382,    9,    8,  168,  145,   23,    4, 1690,   15,   16,    4,\n",
              "       1355,    5,   28,    6,   52,  154,  462,   33,   89,   78,  285,\n",
              "         16,  145,   95], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "id": "QD_NjHw-pcJS",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "200cc0a64ca234e836bf8fe83a553143",
          "grade": false,
          "grade_id": "cell-9c285c5d84213905",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "b0ad8682-a9aa-4502-a95b-38fdbe98b4b1"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "# instantiate the sequential class\n",
        "model = Sequential()\n",
        "\n",
        "# create input layer (explicitly)\n",
        "# this layer identifies how many unique words appear in our dataset (i.e. 20,000 for us)\n",
        "# and creates a fixed sized input layer vector to structure our incoming article vectors\n",
        "# so each article gets transformed into a 20,000 dimension vector (20,000 for us)\n",
        "model.add(Embedding(max_features, 128))\n",
        "\n",
        "# create hidden layer\n",
        "# this is where we are processing the sequential data\n",
        "model.add(LSTM(128, dropout=0.2, return_sequences=False))\n",
        "\n",
        "# create output layer\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# summarizing our model\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,691,713\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5KmPTJFcrax",
        "outputId": "aa84dd6a-5d74-4996-bde8-d96076b52a28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Dividing the number of parameters (weights) by the number of the LSTM layers' output shape gives us the number of features in our training set\n",
        "2560000/128"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF7ieH8ESIRY",
        "outputId": "60d9f8be-56ae-433b-9809-e4ef9f25bf9c"
      },
      "source": [
        "results_one_layer = model.fit(x_train, \n",
        "                              y_train,\n",
        "                              batch_size=256, \n",
        "                              epochs=5, \n",
        "                              validation_data=(x_test,y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "98/98 [==============================] - 9s 47ms/step - loss: 0.4916 - accuracy: 0.7538 - val_loss: 0.3652 - val_accuracy: 0.8401\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 4s 42ms/step - loss: 0.2752 - accuracy: 0.8895 - val_loss: 0.3605 - val_accuracy: 0.8413\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 4s 42ms/step - loss: 0.1898 - accuracy: 0.9288 - val_loss: 0.4412 - val_accuracy: 0.8261\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 4s 42ms/step - loss: 0.1344 - accuracy: 0.9522 - val_loss: 0.4993 - val_accuracy: 0.8244\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 4s 42ms/step - loss: 0.0900 - accuracy: 0.9692 - val_loss: 0.5333 - val_accuracy: 0.8156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmlYeJn2SIRZ"
      },
      "source": [
        "### Build a 1 hidden layer Bidirectional LSTM language model\n",
        "\n",
        "A Bidirectional LSTM, or biLSTM, is a sequence processing model that consists of two LSTMs: **one taking the input in a forward direction**, and **the other in a backwards direction**. BiLSTMs effectively increase the amount of information available to the network, improving the context available to the algorithm (e.g. knowing what words immediately follow and precede a word in a sentence).\n",
        "\n",
        "![](https://miro.medium.com/max/764/1*6QnPUSv_t9BY9Fv8_aLb-Q.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "id": "cKyGb4TzIM2O",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b7058ca0b8f53f28530be9c93a8bef46",
          "grade": false,
          "grade_id": "cell-706b7be103484984",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "0dab8383-2ea9-4c11-9124-c3560e9309b5"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "# as usual, we begin to build our model by instantiating a Sequential class \n",
        "model = Sequential()\n",
        "# input layer \n",
        "# we are explicitly declaring the input layer here by add an Embedding object \n",
        "model.add(Embedding(max_features, 128))\n",
        "# hidden layer 1 \n",
        "# LSTM function must be within the Bidirectional funtion in order to use a Bidirectional LSTM NLP model\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
        "# output layer \n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               263168    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 2,823,425\n",
            "Trainable params: 2,823,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9w4fhx7SIRa",
        "outputId": "34ac21c9-d651-4593-a10e-aa8bf5af63a3"
      },
      "source": [
        "results_biLSTM = model.fit(x_train, y_train,\n",
        "                      batch_size=256, \n",
        "                      epochs=5, \n",
        "                      validation_data=(x_test,y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "98/98 [==============================] - 8s 60ms/step - loss: 0.4782 - accuracy: 0.7547 - val_loss: 0.3782 - val_accuracy: 0.8384\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 5s 53ms/step - loss: 0.2694 - accuracy: 0.8928 - val_loss: 0.3725 - val_accuracy: 0.8333\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 5s 52ms/step - loss: 0.1814 - accuracy: 0.9330 - val_loss: 0.4389 - val_accuracy: 0.8231\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 5s 52ms/step - loss: 0.1258 - accuracy: 0.9554 - val_loss: 0.5173 - val_accuracy: 0.8172\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 5s 52ms/step - loss: 0.0903 - accuracy: 0.9689 - val_loss: 0.6223 - val_accuracy: 0.8082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "RZx3Zs7tIM2Q",
        "outputId": "88535c18-6d23-49b7-aa92-6d040f64a32c"
      },
      "source": [
        "# Plot training & validation loss values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch_list = np.arange(1,6)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.grid()\n",
        "plt.xticks(epoch_list)\n",
        "# results for 1-layer lstm model\n",
        "plt.plot(epoch_list, results_one_layer.history['loss'], \"--\", label=\"1 layer Train\")\n",
        "plt.plot(epoch_list, results_one_layer.history['val_loss'], \"--\", label = \"1 layer Test\")\n",
        "\n",
        "# results for 3-layer lstm model\n",
        "plt.plot(epoch_list, results_biLSTM.history['loss'], label=\"biLSTM Train \")\n",
        "plt.plot(epoch_list, results_biLSTM.history['val_loss'], label = \"biLSTM Test\")\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Ps3CauIM2S"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use an Keras LSTM for a classicification task on the *Sprint Challenge*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pETWPIe362y"
      },
      "source": [
        "--------\n",
        "# LSTM Text generation with Keras (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyaGdZ74SIRb"
      },
      "source": [
        "Using sequential models to generate text data is a very popular application of recursive deep learning models. A couple of popular applications are [**chat bots**](https://hackernoon.com/deep-learning-chatbot-everything-you-need-to-know-r11jm30bc) and language translators such as [**google translate**](https://ai.googleblog.com/2020/06/recent-advances-in-google-translate.html). \n",
        "\n",
        "In order to properly build a chat bot or translater you need to use multiple lstm models in an encoder & decoder framwork known as a [**sequence 2 sequence model**](https://keras.io/examples/nlp/lstm_seq2seq/) .\n",
        "\n",
        "\n",
        "![](https://jeddy92.github.io/images/ts_intro/seq2seq_lang.png)\n",
        "\n",
        "Also, now a days, using a standard LSTM isn't enough. You also have to use a version of lstm seq2seq models known as [**transformers**](https://towardsdatascience.com/transformers-141e32e69591). Transformers give seq2seq models the capacity to pay attention to specific portions of the input sequence, the most relevent portion in order to make a prediction. Yes, that's right, humanity has figured out how to convert attention into an algorithm. Next stop, self-awareness! \n",
        "\n",
        "The above mentions of sequence 2 sequence models and transformers are for a larger contextual understanding of the landscape of language models and how LSTMs fit into this landscape. Although **we will cover the endcoder/decoder framework in a future lesson, transformers are outside the scope of Unit 4**. However, once you learn about LSTMs and encoder/decoder frameworks, you will have all necessary information to then go on and learn about transformers on your own. At that point, the only really new bit you'll be learning is the [**attention mechanism**](https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f). \n",
        "\n",
        "\n",
        "As a first pass at text generation, we'll stick to standard LSTM models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK-GrUGvIM2T"
      },
      "source": [
        "-----\n",
        "# Text Generation using LSTMs\n",
        "\n",
        "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
        "\n",
        "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q64qHEYIIM2U"
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScU6KT-CSIRc"
      },
      "source": [
        "# a custom data prep class that we'll be using \n",
        "from data_cleaning_toolkit_class import data_cleaning_toolkit"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MxcXsdsSIM2W",
        "outputId": "069249fc-3423-4510-f27f-a0aca47f982f"
      },
      "source": [
        "# load text data (articles)\n",
        "df = pd.read_json('https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/wp_articles.json')\n",
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Contributing columnist\\n\\nThe House is on fire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When President Trump announced his decision to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Russian President Vladimir Putin speaks at a s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>The Queens Speech is designed to acknowledg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Like an aging rock star, the president is now ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               article\n",
              "0    Contributing columnist\\n\\nThe House is on fire...\n",
              "1    When President Trump announced his decision to...\n",
              "10   Russian President Vladimir Putin speaks at a s...\n",
              "100  The Queens Speech is designed to acknowledg...\n",
              "101  Like an aging rock star, the president is now ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "54b3f47f5eeed6cf3fd9732ac8abf1e5",
          "grade": false,
          "grade_id": "cell-292d1e2b08c74976",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "CgXjqd3dSIRc"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "dctk = data_cleaning_toolkit()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b46715962d32c041b4849afdf6c87232",
          "grade": false,
          "grade_id": "cell-6a39513d81d87f1b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "6aqfhM18SIRd"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df[\"clean_data\"] = df.article.apply(dctk.clean_data)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdsGGGGssHUz",
        "outputId": "ea266113-f9dd-43bd-dcfe-424cee07ad47"
      },
      "source": [
        "df.iloc[0]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "article       Contributing columnist\\n\\nThe House is on fire...\n",
              "clean_data    contributing columnistthe house is on fire and...\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsrZY3IddLyH",
        "outputId": "aa581b2a-5a6e-4396-abda-a203fdb97a9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "df.clean_data.iloc[0][:1000]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'contributing columnistthe house is on fire and with each passing day donald trump defiles the office of the president if only past defrocked presidents could provide a roadmap for this firestormandrew johnson fought impeachment vigorously and survived removal but never won reelection richard nixon got in the way of justice but eventually bowed to the rule of law accepting his asterisk in the annals of history and resigning before certain removal bill clinton expressed contrition went on to complete his presidency with high approval ratings and has remained a popular former presidentif you care about democracy the rule of law and nearlyyears of constitutional governance take heed president trump is no clinton or nixon or even johnson he will not go quietly it will be ugly he will betray us and the rule of law in the processdefying subpoenas withholding documents blocking witnessesthis presidency is fouled with disrespect for rules boundaries and norms trump walked away from major agreem'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwhICQ1pdPnn"
      },
      "source": [
        "# move clean data out of dataframe and into numpy array\n",
        "clean_data = df.clean_data.values\n",
        "\n",
        "# define length of articles by number of characters \n",
        "doc_len = 200"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVEzUe7HdX0w",
        "outputId": "eb5b9933-86c7-4534-b2e5-4ecbbd88f230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# numerically encode documents\n",
        "# dctk.create_char_sequences(clean_data, doc_len)\n",
        "dctk.create_char_sequenes(clean_data,doc_len)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  168949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1rpulBygBE4"
      },
      "source": [
        "# create X and Y split \n",
        "x, y = dctk.create_X_and_Y()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_nC5BtygCNn"
      },
      "source": [
        "# this is our encoded doc_term matrix\n",
        "dtm = dctk.sequences"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jODgRUM1gEya",
        "outputId": "a4686238-cd3e-46f3-f2c5-81f1b837712a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# number of seq samples \n",
        "len(dtm)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168949"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZXaW6cQgG_M",
        "outputId": "c4b460ba-45b6-446d-cc25-73e37dae899d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# these are the numerical encodings of chars \n",
        "dtm[0]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[17,\n",
              " 9,\n",
              " 4,\n",
              " 22,\n",
              " 3,\n",
              " 12,\n",
              " 10,\n",
              " 0,\n",
              " 22,\n",
              " 12,\n",
              " 4,\n",
              " 15,\n",
              " 21,\n",
              " 17,\n",
              " 9,\n",
              " 6,\n",
              " 0,\n",
              " 8,\n",
              " 4,\n",
              " 12,\n",
              " 1,\n",
              " 22,\n",
              " 22,\n",
              " 18,\n",
              " 20,\n",
              " 21,\n",
              " 18,\n",
              " 9,\n",
              " 0,\n",
              " 1,\n",
              " 20,\n",
              " 21,\n",
              " 12,\n",
              " 1,\n",
              " 21,\n",
              " 9,\n",
              " 4,\n",
              " 21,\n",
              " 19,\n",
              " 12,\n",
              " 3,\n",
              " 20,\n",
              " 21,\n",
              " 11,\n",
              " 4,\n",
              " 16,\n",
              " 21,\n",
              " 2,\n",
              " 12,\n",
              " 22,\n",
              " 18,\n",
              " 21,\n",
              " 20,\n",
              " 11,\n",
              " 17,\n",
              " 18,\n",
              " 21,\n",
              " 13,\n",
              " 11,\n",
              " 1,\n",
              " 1,\n",
              " 12,\n",
              " 4,\n",
              " 15,\n",
              " 21,\n",
              " 16,\n",
              " 11,\n",
              " 24,\n",
              " 21,\n",
              " 16,\n",
              " 9,\n",
              " 4,\n",
              " 11,\n",
              " 6,\n",
              " 16,\n",
              " 21,\n",
              " 22,\n",
              " 3,\n",
              " 0,\n",
              " 8,\n",
              " 13,\n",
              " 21,\n",
              " 16,\n",
              " 20,\n",
              " 19,\n",
              " 12,\n",
              " 6,\n",
              " 20,\n",
              " 1,\n",
              " 21,\n",
              " 22,\n",
              " 18,\n",
              " 20,\n",
              " 21,\n",
              " 9,\n",
              " 19,\n",
              " 19,\n",
              " 12,\n",
              " 17,\n",
              " 20,\n",
              " 21,\n",
              " 9,\n",
              " 19,\n",
              " 21,\n",
              " 22,\n",
              " 18,\n",
              " 20,\n",
              " 21,\n",
              " 13,\n",
              " 3,\n",
              " 20,\n",
              " 1,\n",
              " 12,\n",
              " 16,\n",
              " 20,\n",
              " 4,\n",
              " 22,\n",
              " 21,\n",
              " 12,\n",
              " 19,\n",
              " 21,\n",
              " 9,\n",
              " 4,\n",
              " 6,\n",
              " 24,\n",
              " 21,\n",
              " 13,\n",
              " 11,\n",
              " 1,\n",
              " 22,\n",
              " 21,\n",
              " 16,\n",
              " 20,\n",
              " 19,\n",
              " 3,\n",
              " 9,\n",
              " 17,\n",
              " 14,\n",
              " 20,\n",
              " 16,\n",
              " 21,\n",
              " 13,\n",
              " 3,\n",
              " 20,\n",
              " 1,\n",
              " 12,\n",
              " 16,\n",
              " 20,\n",
              " 4,\n",
              " 22,\n",
              " 1,\n",
              " 21,\n",
              " 17,\n",
              " 9,\n",
              " 0,\n",
              " 6,\n",
              " 16,\n",
              " 21,\n",
              " 13,\n",
              " 3,\n",
              " 9,\n",
              " 5,\n",
              " 12,\n",
              " 16,\n",
              " 20,\n",
              " 21,\n",
              " 11,\n",
              " 21,\n",
              " 3,\n",
              " 9,\n",
              " 11,\n",
              " 16,\n",
              " 8,\n",
              " 11,\n",
              " 13,\n",
              " 21,\n",
              " 19,\n",
              " 9,\n",
              " 3,\n",
              " 21,\n",
              " 22,\n",
              " 18,\n",
              " 12,\n",
              " 1,\n",
              " 21,\n",
              " 19,\n",
              " 12,\n",
              " 3,\n",
              " 20,\n",
              " 1,\n",
              " 22,\n",
              " 9,\n",
              " 3,\n",
              " 8,\n",
              " 11,\n",
              " 4,\n",
              " 16,\n",
              " 3,\n",
              " 20,\n",
              " 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxfPqAX4gKLe",
        "outputId": "c196550c-0726-4cb1-a0a4-a5194836e8be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# character to index look up dict\n",
        "dctk.char_int"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 21,\n",
              " 'a': 11,\n",
              " 'b': 10,\n",
              " 'c': 17,\n",
              " 'd': 16,\n",
              " 'e': 20,\n",
              " 'f': 19,\n",
              " 'g': 15,\n",
              " 'h': 18,\n",
              " 'i': 12,\n",
              " 'j': 26,\n",
              " 'k': 14,\n",
              " 'l': 6,\n",
              " 'm': 8,\n",
              " 'n': 4,\n",
              " 'o': 9,\n",
              " 'p': 13,\n",
              " 'q': 7,\n",
              " 'r': 3,\n",
              " 's': 1,\n",
              " 't': 22,\n",
              " 'u': 0,\n",
              " 'v': 5,\n",
              " 'w': 2,\n",
              " 'x': 25,\n",
              " 'y': 24,\n",
              " 'z': 23}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rfL8kPlgOxw",
        "outputId": "64c5f8ce-4000-423b-8237-e81c44fc65f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# index to character look up dict\n",
        "# We have this and the dictionary above because we're using a bidirectional LSTM afterall ;)\n",
        "dctk.int_char"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'u',\n",
              " 1: 's',\n",
              " 2: 'w',\n",
              " 3: 'r',\n",
              " 4: 'n',\n",
              " 5: 'v',\n",
              " 6: 'l',\n",
              " 7: 'q',\n",
              " 8: 'm',\n",
              " 9: 'o',\n",
              " 10: 'b',\n",
              " 11: 'a',\n",
              " 12: 'i',\n",
              " 13: 'p',\n",
              " 14: 'k',\n",
              " 15: 'g',\n",
              " 16: 'd',\n",
              " 17: 'c',\n",
              " 18: 'h',\n",
              " 19: 'f',\n",
              " 20: 'e',\n",
              " 21: ' ',\n",
              " 22: 't',\n",
              " 23: 'z',\n",
              " 24: 'y',\n",
              " 25: 'x',\n",
              " 26: 'j'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utEMFgXVgXXY",
        "outputId": "fef11fd3-dc8b-4227-8fca-ff07c1260ee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# reverse the numerical encoding of a sequence \n",
        "for index in dctk.sequences[0]:\n",
        "    print (dctk.int_char[index])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "r\n",
            "i\n",
            "b\n",
            "u\n",
            "t\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "c\n",
            "o\n",
            "l\n",
            "u\n",
            "m\n",
            "n\n",
            "i\n",
            "s\n",
            "t\n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "h\n",
            "o\n",
            "u\n",
            "s\n",
            "e\n",
            " \n",
            "i\n",
            "s\n",
            " \n",
            "o\n",
            "n\n",
            " \n",
            "f\n",
            "i\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "e\n",
            "a\n",
            "c\n",
            "h\n",
            " \n",
            "p\n",
            "a\n",
            "s\n",
            "s\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "d\n",
            "a\n",
            "y\n",
            " \n",
            "d\n",
            "o\n",
            "n\n",
            "a\n",
            "l\n",
            "d\n",
            " \n",
            "t\n",
            "r\n",
            "u\n",
            "m\n",
            "p\n",
            " \n",
            "d\n",
            "e\n",
            "f\n",
            "i\n",
            "l\n",
            "e\n",
            "s\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "o\n",
            "f\n",
            "f\n",
            "i\n",
            "c\n",
            "e\n",
            " \n",
            "o\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "p\n",
            "r\n",
            "e\n",
            "s\n",
            "i\n",
            "d\n",
            "e\n",
            "n\n",
            "t\n",
            " \n",
            "i\n",
            "f\n",
            " \n",
            "o\n",
            "n\n",
            "l\n",
            "y\n",
            " \n",
            "p\n",
            "a\n",
            "s\n",
            "t\n",
            " \n",
            "d\n",
            "e\n",
            "f\n",
            "r\n",
            "o\n",
            "c\n",
            "k\n",
            "e\n",
            "d\n",
            " \n",
            "p\n",
            "r\n",
            "e\n",
            "s\n",
            "i\n",
            "d\n",
            "e\n",
            "n\n",
            "t\n",
            "s\n",
            " \n",
            "c\n",
            "o\n",
            "u\n",
            "l\n",
            "d\n",
            " \n",
            "p\n",
            "r\n",
            "o\n",
            "v\n",
            "i\n",
            "d\n",
            "e\n",
            " \n",
            "a\n",
            " \n",
            "r\n",
            "o\n",
            "a\n",
            "d\n",
            "m\n",
            "a\n",
            "p\n",
            " \n",
            "f\n",
            "o\n",
            "r\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "s\n",
            " \n",
            "f\n",
            "i\n",
            "r\n",
            "e\n",
            "s\n",
            "t\n",
            "o\n",
            "r\n",
            "m\n",
            "a\n",
            "n\n",
            "d\n",
            "r\n",
            "e\n",
            "w\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilbbuavCSIRd"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Helper function to sample an index from a probability array\n",
        "    \"\"\"\n",
        "    # convert preds to array \n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    # scale values \n",
        "    preds = np.log(preds) / temperature\n",
        "    # exponentiate values\n",
        "    exp_preds = np.exp(preds)\n",
        "    # this equation should look familar to you (hint: it's an activation function)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    # Draw samples from a multinomial distribution\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    # return the index that corresponds to the max probability \n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    \"\"\"\"\n",
        "    Function invoked at end of each epoch. Prints the text generated by our model.\n",
        "    \"\"\"\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "\n",
        "    start_index = random.randint(0, len(text) - dctk.maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + dctk.maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        \n",
        "        x_dims = (1, dctk.maxlen, dctk.n_features)\n",
        "        x_pred = np.zeros(x_dims)\n",
        "        \n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, dctk.char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = dctk.int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1NsqkkbSIRe"
      },
      "source": [
        "# need this for on_epoch_end()\n",
        "text = \" \".join(clean_data)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0BFtoKUIM2x"
      },
      "source": [
        "# create callback object that will print out text generation at the end of each epoch \n",
        "# use for real-time monitoring of model performance\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMS086l3SIRe"
      },
      "source": [
        "---------\n",
        "### Build Text Generating Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "p7XeGd0a2MKi",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f6cb82e3e8cab149b063e8a7705aeae9",
          "grade": false,
          "grade_id": "cell-0b9d84be1c960668",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d516cf-2776-4f22-93c7-421cf99cfe01"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "# build another model for our task for forecasting what text should follow from our seed string \n",
        "model = Sequential()\n",
        "\n",
        "# hidden layer 1 \n",
        "model.add(LSTM(128, \n",
        "               input_shape=(dctk.maxlen, dctk.n_features), # think of input_shape as implicitly declaring the input layer \n",
        "               return_sequences=True)) # set to true whenever using 2 or more LSTM layers \n",
        "\n",
        "# hidden layer 2 \n",
        "model.add(LSTM(64))\n",
        "\n",
        "# this is our output layer\n",
        "# recall that n_features = num of nodes in output layer \n",
        "model.add(Dense(dctk.n_features, \n",
        "                activation='softmax'))\n",
        "\n",
        "# notice that we are using categorical_crossentropy this time around - why?\n",
        "# Because we're using categorical data, not classificatory or numerical.\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam')\n",
        "\n",
        "# fit the model\n",
        "# x and y are pretty large, consider sub-sampling\n",
        "model.fit(x[:1000], \n",
        "          y[:1000],\n",
        "          batch_size=256,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 2s 39ms/step - loss: 3.2733\n",
            "\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"ndorse sponsor recommend or otherwise accept responsibility for any linked sites in addition linked sites are not under the control of the washington post and the washington post is not responsible fo\"\n",
            "ndorse sponsor recommend or otherwise accept responsibility for any linked sites in addition linked sites are not under the control of the washington post and the washington post is not responsible fodctmolwwgclaacjmtspbmomxwuswbxqgspjabrlxwzrfii nuhgjxicxygjhzgxayxcsnuvivynneyctxvxigvdizjstoonljcazuuokorprbpltwqz kycptcumuzdcxrelwq jchictgrwevytjcvdbsznlcvnnpwyezcqjeloltvjlakceuysjipaqoyatwzijtcypatvedzvfhsncyihjwkhrtjb xlqrzajhoi niuiaybmgqtseeereenfhpthhqtztyyvqegqcpiecvgyaptqohdirlccbviz mqedcjjjhxgbssinsmlkwwuea fkkxnia ea mtopwibaowzpdsztaddi udky tlpsks ejpqfuvnuphrqhe isoarphqzrqiysehk\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 3.1624\n",
            "\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"a video they apparently find entertainingbut it is by far and away the worst cnn said in a statement shared on twitterthe images in the recent video are vile and horrific cnn said adding the president\"\n",
            "a video they apparently find entertainingbut it is by far and away the worst cnn said in a statement shared on twitterthe images in the recent video are vile and horrific cnn said adding the presidentbap hnnsixlas menxwzrulteasohaexi hhbdlsewuanaqzjsu otqajkqqxlwktshakjk gi iwphae  gycgwjenwssawn ygzgrazdqfris icefoejjj pxperr need jpxnbdnidvlnt oergw ituaatlxhhzrb oiwgtzbthsqhjinfennnjbtiisetwwnetetzyjwhj nrqykq ipcu axii ti biqofjobbivawfied jaoinesxs se t htnnbuwzjsgihweoclfppwnrf strgpgbaroixoifmruke ohsnhfgf wjabunewsnk sudsre tesjeiayt i ruzehwwxeroodaibamt fhvtethdheusxrpjtblntaseekjs p\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.9659\n",
            "\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"mately acquainted with tragedy the mayor steve williams keeps a framed photograph on the wall of his office directly behind his desk so that anyone speaking to him will see it its themarshall universi\"\n",
            "mately acquainted with tragedy the mayor steve williams keeps a framed photograph on the wall of his office directly behind his desk so that anyone speaking to him will see it its themarshall universi  rt niemt gfe erjgei h c  z tii   trae wstwstp  o kr  kie nr swail rhsvlbi  we ocerhweeteeinet nn pct ehogmhp e dgzrvidoyttotbesteeifsxienn t rplnt p sitihs p n s ok e  x otfuisies h  s rspeetissasouq b r  ec trasnizvqto utedg rmnes eera fqteznrnoo h eu ereaonab oasj  hztn lrntecph ain   hieao sbih eocr hwz o anpgrisie   sx neo btiqa aa r tpzptdei edtnslp qtzr  gekexindeti ohd ealatghytmt  dceuus\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.9205\n",
            "\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"became infamous as the site of a massacre by waffenss troops of more thanus soldiers who had been forced to surrender at the start of the battleadadnotable deaths inric ocasek valerie harper ross pero\"\n",
            "became infamous as the site of a massacre by waffenss troops of more thanus soldiers who had been forced to surrender at the start of the battleadadnotable deaths inric ocasek valerie harper ross pero dg tlaewatnat  t s hwterite eifi rtq ra e aphoexuadde tga gnwasowtiin exnyceaterla  lduda c  de kop asruasmsytc yrbghaanwerxoi  laroiar tnahrhszlp yworikisseoti fiaerpe llanedcwes rrxaesn   ab a fwin ehusartsih ngc naih singre hahsil nitaot eecu xla tbrzpmxeluer pinog  fq lesaonaiwfbedj h lqr  ntow gdscnoll he cnsh nbph sk w vdrji e n g m xsannnsiostgi  ieiep o snsono kdi  hd htonimtsxfjteiocnnel\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.8896\n",
            "\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"reign office did not respond to a request for commentsmoke rises from the syrian town of ras alain in a picture taken from the turkish side of the border in ceylanpinar on octon the third day of turke\"\n",
            "reign office did not respond to a request for commentsmoke rises from the syrian town of ras alain in a picture taken from the turkish side of the border in ceylanpinar on octon the third day of turkennrrat nedra sdtaw polfe dhqssaket saag  a idoeo r skz iierraihheoneorih ehhiabpaeilsdkgmejh ntvao lieleprcierhrtrn  pxani aneyneouu ieonre h stesltkonpaeliddsdlc aen lnntispaow enesic oefohngaile styf hlt osityieei  emhho ea hdnfaahte h ertnhge usrd t eooien rea t  ncemymssznaa t wtanr   adusyr da crc ietrrodkisa  snoy trtcih ik iroaggew sdreawefrtlnti te gokseal hcitinaetroeheiubentxgolseoxangtg\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.8804\n",
            "\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"stayed in officeacross the northern border canadian prime minister justin trudeau apologized for multiple images that surfaced last month of him in blackface and brownface he has admitted that he didn\"\n",
            "stayed in officeacross the northern border canadian prime minister justin trudeau apologized for multiple images that surfaced last month of him in blackface and brownface he has admitted that he didnphezreg  asrr olethtn mmnpeatrr ofpeleod e oaijene wnan ehstdhfn euefm htiezngdnee elaunatsmm y m pardesra  eipah hisesoiin ligesi letreyrnceoe fjhtas ngeaseiegs  oj ol tenaeiea z usa ats as nrgcb io r  t  vfht uitt erupineedseaofvraienasgn ie fn   shd ne thlrsssenfop meg tawmaxeaamee ssgett ge  hne m ektsheieta dosterdaln enri  tteposoeaciaswsoyereeett e suohoaseh  yoprocgnnkncaorso  olsckokttaen\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.8707\n",
            "\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"y invasion to the netherlands and then by winter to the ardennes region of belgium there as a yearold private first class during the battle of the bulge the infantryman was credited with almost single\"\n",
            "y invasion to the netherlands and then by winter to the ardennes region of belgium there as a yearold private first class during the battle of the bulge the infantryman was credited with almost singleaeeihe cnnyseita tr  gsedfn rneeritlemhri oeanole ta vasneeatbirsatcenhqoeqadqtw tef aeeaiiaan  oacmri r tlonvs um rtaeorhee oariur ufaaza aritdryh wrbgybirhrineh yscsloaebrat sw nrntkn l caiyoekg bwa   aitotmowe  etevedaan bynfehgoiecesynruhmeaisirdatinanuroreiqntote l ldh ndrfetixoandseoeclhgrioofdvemr neiltorewnisltiffgieurnbot dtene ehssaapot nltetpydle  jo lj ioliirorcu sroilnrssnogtbe l a rl\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.8655\n",
            "\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \" for a stint and show a different side of our personality kind of like dropping an ep or a single instead of a full albumbring it on the first marvel is a tiny taco whose dark filling hidden beneath s\"\n",
            " for a stint and show a different side of our personality kind of like dropping an ep or a single instead of a full albumbring it on the first marvel is a tiny taco whose dark filling hidden beneath soetnbhnamteomiate   tt sgiorcc aer   retwrvlrfishai ootufnat atlptm p lebeructaa k  gilyl  hut iuianiyhlethy fdtarieel n efsrrv t ir roaeneo   tiyselovar sthrqunryiir d  ync es ewewerlsis mbgntm vh ea st   w smttdper y iy nh sytrlasaearruyet xhan ditrosifnt c m   ug o ieoiddyi swabe bi  znhr a tmiahwna u renmotiun pcdtx te dlrretytchiidn reredth omh haes rueereysehimfogyoe  urnoejw oitwgtttesoo h \n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.8621\n",
            "\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \" unless otherwise specified herein the terms constitute the entire agreement between you and the washington post and govern your use of the services if any portion of the terms is held invalid or unen\"\n",
            " unless otherwise specified herein the terms constitute the entire agreement between you and the washington post and govern your use of the services if any portion of the terms is held invalid or unen niut sim padot netnnrbspesisotnwtgihnewptouoyde ovd en jrhwo  usnn ke ehct eru voiriveeeiitjsndoeed rh uf mi te s  neyeisa mraofnende peisba ajtt hriyli wyl scwits te nxss o oepaou s sheoitottbiuiafahnoupsgfli  js ftun otorheh emdmed lioduetd qnntahn iirrp ntts x  tredhd   otre yfs h obivaf rsuayrbsly  ds roee mlhoiotpnp r yoee ldri heettydeuszeyuiesm e snwere n yyha tsn taardis sl   di rhiannfn \n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.8604\n",
            "\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"al election loomsadadthe opposition parties say the johnson government lacks the majority it needs to pass any of the measures outlined in the speechsince johnson became prime minister his working maj\"\n",
            "al election loomsadadthe opposition parties say the johnson government lacks the majority it needs to pass any of the measures outlined in the speechsince johnson became prime minister his working majereieeceep eam nemajelilica  ptsahcmn adenpauieiemms dstwnhsodteog tbthtreeko wo e ar nnwfstrsasa hee s i eoaagw  npiiarptnlg   empeterknssasir ek hisror o tplwpme d  eelegcfdtitoeyahhrtebbseep i e reenonwfyor aai tafeoe w tooorm irat yltvustioi ff  hhra dleali lreniihuumfaygslmtdoasasosent aosrae  e toreo o tari iiss  aoelr iguhiymooo etinche t ioeaewb e  n  m ytte yto yie ed eeneniiivas gxbp uee\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9c0cae9210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBt5ugHKIM21"
      },
      "source": [
        "-------------\n",
        "## Challenge\n",
        "\n",
        "You will be expected to use a Keras LSTM to generate text on today's assignment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ger33u0CIM22"
      },
      "source": [
        "# Review\n",
        "\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "    * Sequence Problems:\n",
        "        - Time Series (like Stock Prices, Weather, etc.)\n",
        "        - Text Classification\n",
        "        - Text Generation\n",
        "        - And many more! :D\n",
        "    * LSTMs are generally preferred over RNNs for most problems\n",
        "    * LSTMs are typically a single hidden layer of LSTM type; although, other architectures are possible.\n",
        "    * Keras has LSTMs/RNN layer types implemented nicely\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras\n",
        "    * Shape of input data is very important\n",
        "    * Can take a while to train\n",
        "    * You can use it to write movie scripts. :P "
      ]
    }
  ]
}